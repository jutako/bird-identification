{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d4d2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from classifier import Classifier\n",
    "from functions import calibrate, adjust, threshold_filter\n",
    "\n",
    "# PARAMS needed from recording metadata:\n",
    "# lat: latitude\n",
    "# lon: longitude\n",
    "# day: day of the year 1-365\n",
    "\n",
    "threshold = 0.3 # only save predictions with confidence higher than threshold\n",
    "\n",
    "# some mockup-values for prediction calibration:\n",
    "lat = 65.00 # latitude\n",
    "lon = 24.00 # longitude\n",
    "day = 150   # day of year 1-365\n",
    "\n",
    "# load classification model\n",
    "# TFLITE_THREADS can be as high as number of CPUs available, the rest of the parameters should not be changed\n",
    "clsf = Classifier(path_to_model='model_v3/model_v3_5.keras', sr=48000, clip_dur=3.0, TFLITE_THREADS = 1, offset=0, dur=0) \n",
    "\n",
    "# load species list and post-processing tables for prediction calibration\n",
    "sp_list=pd.read_csv(\"classes.csv\")\n",
    "migr_table = np.load('Pred_adjustment/migration_params.npy')\n",
    "cal_table = np.load('Pred_adjustment/calibration_params.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91ed1467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 1.wav (1/5)...\n",
      "Loading file data/1.wav...\n",
      "Classifying recording...\n",
      "Recording analyzed!\n",
      "Analyzing 2.wav (2/5)...\n",
      "Loading file data/2.wav...\n",
      "Classifying recording...\n",
      "Recording analyzed!\n",
      "Analyzing 3.wav (3/5)...\n",
      "Loading file data/3.wav...\n",
      "Classifying recording...\n",
      "Recording analyzed!\n",
      "Analyzing 5.wav (4/5)...\n",
      "Loading file data/5.wav...\n",
      "Classifying recording...\n",
      "Recording analyzed!\n",
      "Analyzing 4.wav (5/5)...\n",
      "Loading file data/4.wav...\n",
      "Classifying recording...\n",
      "Recording analyzed!\n",
      " \n",
      "All files analyzed\n",
      "Results saved to data_results.txt\n"
     ]
    }
   ],
   "source": [
    "# define path to audio data\n",
    "path = \"data\"\n",
    "\n",
    "# analyze all files\n",
    "files = os.listdir(path)\n",
    "\n",
    "with open(path + '_results.txt', 'a') as f:\n",
    "    f.write(\"site, file, species, prediction, detection_time \\n\")\n",
    "\n",
    "n_files = len(files)\n",
    "for j, fi in enumerate(files):\n",
    "    try:\n",
    "        print(f\"Analyzing {fi} ({j+1}/{n_files})...\")\n",
    "        # predict for example clip\n",
    "        pred, t = clsf.classify(path + '/' + fi, max_pred=False) #max_pred: only keep highest confidence detection for each species instead of saving all detections\n",
    "        # calibrate prediction \n",
    "        for i in range(len(pred)):\n",
    "            pred[i, :] = calibrate(pred[i, :], cal_table=cal_table)\n",
    "        # ignore human and noise predictions\n",
    "        pred[:,0:2] = 0 \n",
    "        # filter predictions with a threshold \n",
    "        pred, c, t = threshold_filter(pred, t, threshold)\n",
    "        # adjust prediction based on time of the year and latitude (only if record is from Finland and location and date are known)\n",
    "        pred = adjust(pred, c, migr_table, lat, lon, day) \n",
    "        # filter and find species names from sp_list\n",
    "        for i in range(len(pred)):\n",
    "            if c[i] > 1: # ignore two first classes: noise and human\n",
    "                with open(path + '_results.txt', 'a') as f:\n",
    "                    f.write(path + \", \" + fi + \", \" + str(sp_list['common_name'].iloc[c[i]]) + \", \" + str(pred[i]) + \", \" + str(t[i]) + \"\\n\")\n",
    "        gc.collect() # clear memory\n",
    "    except: \n",
    "        print(f\"Error analyzing {fi}!\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"All files analyzed\")\n",
    "print(f\"Results saved to {path}_results.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
